{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n",
      "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
      "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
      "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
      "       'Class'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('creditcard.csv')\n",
    "print(df.shape)\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:\n",
      "\n",
      "count    284807.000000\n",
      "mean      94813.859575\n",
      "std       47488.145955\n",
      "min           0.000000\n",
      "25%       54201.500000\n",
      "50%       84692.000000\n",
      "75%      139320.500000\n",
      "max      172792.000000\n",
      "Name: Time, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Time:\\n\")\n",
    "print(df['Time'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount:\n",
      "\n",
      "count    284807.000000\n",
      "mean         88.349619\n",
      "std         250.120109\n",
      "min           0.000000\n",
      "25%           5.600000\n",
      "50%          22.000000\n",
      "75%          77.165000\n",
      "max       25691.160000\n",
      "Name: Amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Amount:\\n\")\n",
    "print(df['Amount'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class:\n",
      "\n",
      "count    284807.000000\n",
      "mean          0.001727\n",
      "std           0.041527\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.000000\n",
      "75%           0.000000\n",
      "max           1.000000\n",
      "Name: Class, dtype: float64\n",
      "Class\n",
      "0    284315\n",
      "1       492\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Class:\\n\")\n",
    "print(df['Class'].describe())\n",
    "print(df['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Time         V1         V2        V3        V4        V5  \\\n",
      "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
      "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
      "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
      "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
      "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
      "...          ...        ...        ...       ...       ...       ...   \n",
      "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
      "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
      "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
      "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
      "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
      "\n",
      "              V6        V7        V8        V9  ...       V21       V22  \\\n",
      "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
      "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
      "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
      "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
      "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
      "...          ...       ...       ...       ...  ...       ...       ...   \n",
      "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
      "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
      "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
      "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
      "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
      "\n",
      "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
      "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
      "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
      "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
      "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
      "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
      "...          ...       ...       ...       ...       ...       ...     ...   \n",
      "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
      "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
      "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
      "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
      "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
      "\n",
      "        Class  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n",
      "...       ...  \n",
      "284802      0  \n",
      "284803      0  \n",
      "284804      0  \n",
      "284805      0  \n",
      "284806      0  \n",
      "\n",
      "[284807 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## graph construction\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(492, 31)\n",
      "(4920, 31)\n",
      "Cosine similarity calculation completed and saved.\n"
     ]
    }
   ],
   "source": [
    "fraud_data=df[df['Class']==1]\n",
    "normal_data=df[df['Class']==0].sample(n=len(fraud_data)*10,random_state=42)\n",
    "print(fraud_data.shape)\n",
    "print(normal_data.shape)\n",
    "selected_df=pd.concat([normal_data,fraud_data])\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 假設 df 是你的 DataFrame，columns 是要標準化的欄位名稱列表\n",
    "columns_to_normalize = ['Time', 'Amount']  # 填入要標準化的欄位名稱\n",
    "\n",
    "# 初始化 StandardScaler 物件\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 對指定列進行標準化\n",
    "selected_df[columns_to_normalize] = scaler.fit_transform(selected_df[columns_to_normalize])\n",
    "features=selected_df.drop(\"Class\",axis=1)\n",
    "cos_sim=cosine_similarity(features)\n",
    "np.save(\"cos_sim.npy\",cos_sim)\n",
    "print(\"Cosine similarity calculation completed and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -0.10474847 -0.17063587 ...  0.00880987  0.19544622\n",
      "   0.52532881]\n",
      " [-0.10474847  1.          0.35448425 ... -0.07256405 -0.13313727\n",
      "  -0.33534979]\n",
      " [-0.17063587  0.35448425  1.         ... -0.11640662 -0.14318716\n",
      "  -0.26465308]\n",
      " ...\n",
      " [ 0.00880987 -0.07256405 -0.11640662 ...  1.          0.89628544\n",
      "   0.18719061]\n",
      " [ 0.19544622 -0.13313727 -0.14318716 ...  0.89628544  1.\n",
      "   0.22006893]\n",
      " [ 0.52532881 -0.33534979 -0.26465308 ...  0.18719061  0.22006893\n",
      "   1.        ]]\n",
      "(5412, 5412)\n"
     ]
    }
   ],
   "source": [
    "cos_sim=np.load(\"cos_sim.npy\")\n",
    "print(cos_sim)\n",
    "print(cos_sim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics of row statistics:\n",
      "  Max: 1.000000000000001\n",
      "  Min: -0.8610622522995957\n",
      "  Median: -0.020403275449845982\n",
      "  Mean: 0.007676525874176422\n",
      "  Std: 0.031593458544467296\n"
     ]
    }
   ],
   "source": [
    "# 計算每一列的統計量\n",
    "max_values = np.max(cos_sim, axis=1)\n",
    "min_values = np.min(cos_sim, axis=1)\n",
    "median_values = np.median(cos_sim, axis=1)\n",
    "mean_values = np.mean(cos_sim, axis=1)\n",
    "std_values = np.std(cos_sim, axis=1)\n",
    "\n",
    "# 對這些統計量再次計算統計量\n",
    "stats_max = np.max(max_values)\n",
    "stats_min = np.min(min_values)\n",
    "stats_median = np.median(median_values)\n",
    "stats_mean = np.mean(mean_values)\n",
    "stats_std = np.std(std_values)\n",
    "\n",
    "# 印出結果\n",
    "print(\"Statistics of row statistics:\")\n",
    "print(\"  Max:\", stats_max)\n",
    "print(\"  Min:\", stats_min)\n",
    "print(\"  Median:\", stats_median)\n",
    "print(\"  Mean:\", stats_mean)\n",
    "print(\"  Std:\", stats_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graph Construction...: 100%|██████████| 5412/5412 [00:07<00:00, 772.32it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 5412\n",
      "Number of edges: 2495539\n",
      "0.1704350981951714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "G=nx.Graph()\n",
    "nodes_list = []\n",
    "for i in range(cos_sim.shape[0]):\n",
    "    nodes_list.append((i, {'feature': features.values[i]}))\n",
    "G.add_nodes_from(nodes_list)\n",
    "\n",
    "\n",
    "for i in tqdm(range(cos_sim.shape[0]),desc=\"Graph Construction...\"):\n",
    "    for j in range(i+1,cos_sim.shape[1]):\n",
    "        if cos_sim[i,j]>stats_median+stats_std*8:\n",
    "            G.add_edge(i,j)\n",
    "print(\"Number of nodes:\",G.number_of_nodes())\n",
    "print(\"Number of edges:\",G.number_of_edges())\n",
    "density=2*G.number_of_edges()/(G.number_of_nodes()*(G.number_of_nodes()-1))\n",
    "print(density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "selected_df.reset_index(drop=True,inplace=True)\n",
    "# print(selected_df['Class'])\n",
    "\n",
    "for node in G.nodes():\n",
    "    # print(node)\n",
    "    node_class=selected_df.loc[node,'Class']\n",
    "    G.nodes[node]['Class']=node_class\n",
    "\n",
    "# 檢查每個節點的 Class 屬性\n",
    "\n",
    "# 使用 nx.degree() 函數計算每個節點的度\n",
    "node_degrees = dict(nx.degree(G))\n",
    "\n",
    "# 使用 Counter 類對節點的度進行統計\n",
    "# degree_counts = Counter(node_degrees.values())\n",
    "\n",
    "# # 印出結果\n",
    "# print(\"Degree statistics:\")\n",
    "# for degree, count in sorted(degree_counts.items()):\n",
    "#     print(\"Degree:\", degree, \"Count:\", count)\n",
    "\n",
    "# # 找出所有類別為 1 的節點\n",
    "# class_1_nodes = [node for node, data in G.nodes(data=True) if data.get('Class') == 1]\n",
    "\n",
    "# # 計算這些節點的度\n",
    "# class_1_degrees = {node: G.degree(node) for node in class_1_nodes}\n",
    "\n",
    "# # 印出結果\n",
    "\n",
    "# for node, degree in class_1_degrees.items():\n",
    "#     print(\"Node:\", node, \"Degree:\", degree)\n",
    "# print(len(class_1_degrees.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p76121194/miniconda3/envs/dl_project/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2365,  1.3145,  0.5906, -0.6666,  0.7166,  0.3020, -1.1255,  0.3889,\n",
      "        -0.2884, -0.1321, -0.5977, -0.3253, -0.2164,  0.0842, -1.0546,  0.9679,\n",
      "         0.6012,  0.6311,  0.2951, -0.1362, -0.0580, -0.1703, -0.4297, -0.1413,\n",
      "        -0.2002,  0.6395,  0.3995, -0.0343,  0.0317, -0.3871])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_61633/4107390831.py:8: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  x = torch.tensor([node[1] for node in G.nodes.data('feature')], dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "# 轉換為 PyTorch 張量\n",
    "edge_index = torch.tensor(list(G.edges)).t().contiguous()\n",
    "x = torch.tensor([node[1] for node in G.nodes.data('feature')], dtype=torch.float32)\n",
    "# 精度被吃掉？？\n",
    "print(x[0])\n",
    "y = torch.tensor([node[1] for node in G.nodes.data('Class')], dtype=torch.long)  # 節點的標籤\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv\n",
    "import torch.nn.functional as F\n",
    "class Encoder_GAT(torch.nn.Module):\n",
    "    def __init__(self, num_heads, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(Encoder_GAT, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for i in range(self.num_layers-1):\n",
    "            if i:\n",
    "                conv = GATConv(hidden_dim * num_heads, hidden_dim, heads=num_heads)\n",
    "            else:\n",
    "                conv = GATConv(input_dim, hidden_dim, heads=num_heads)\n",
    "\n",
    "            self.convs.append(conv)\n",
    "        conv = GATConv(hidden_dim * num_heads, output_dim)\n",
    "        self.convs.append(conv)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        xs = []\n",
    "        for i in range(self.num_layers):\n",
    "            x = F.relu(self.convs[i](x, edge_index))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class myGNN(nn.Module):\n",
    "    def __init__(self, enc_num_heads, enc_input_dim, enc_hidden_dim, enc_num_layers, linear_output_dim):\n",
    "        super(myGNN, self).__init__()\n",
    "        # GAT(input、output大小一樣)\n",
    "        self.encoder_neighbor = Encoder_GAT(enc_num_heads, enc_input_dim, enc_hidden_dim, enc_input_dim, enc_num_layers)\n",
    "        # linear層\n",
    "        self.proj_head_neighbor = nn.Linear(enc_input_dim, linear_output_dim)\n",
    "        self.proj_head_ego = nn.Linear(enc_input_dim, linear_output_dim)\n",
    "\n",
    "        self.init_emb()\n",
    "    # embedding初始化\n",
    "    def init_emb(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "                # BIASE初始化為0\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(0.0)\n",
    "    @staticmethod\n",
    "    def negative_sample(h_ego, h_neighbor):\n",
    "        # 返回一个0~n-1的数组，随机打散的\n",
    "        perm = torch.randperm(h_ego.shape[0])\n",
    "        # 打亂，作ego-ego negative\n",
    "        h_ego_neg = h_ego[perm]\n",
    "        # 打亂，作ego-neigbor negative\n",
    "        h_neighbor_neg = h_neighbor[perm]\n",
    "        return h_ego_neg, h_neighbor_neg\n",
    "\n",
    "    # @staticmethod\n",
    "    # def cosine_similarity(x1, x2):\n",
    "    #     return torch.div(torch.sum(x1 * x2,0),torch.sqrt(torch.sum(torch.pow(x1,2),0))* torch.sqrt(torch.sum(torch.pow(x2,2),0))).item()\n",
    "\n",
    "    @staticmethod\n",
    "    def discriminator(x1, x2):\n",
    "        return -1 * F.cosine_similarity(x1, x2, dim=1).unsqueeze(0)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # GAT\n",
    "        h_neighbor = self.encoder_neighbor(x, edge_index)\n",
    "        h_neighbor = self.proj_head_neighbor(h_neighbor)\n",
    "        # linear\n",
    "        h_ego = self.proj_head_ego(x)\n",
    "\n",
    "        return h_ego, h_neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import json\n",
    "import copy\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def rescale(x):\n",
    "    return (x + 1) / 2\n",
    "\n",
    "def train_model(args, data, model, optimizer, loss_function):\n",
    "    stats = {\n",
    "        \"best_loss\": 1e9,\n",
    "        \"best_epoch\": -1,\n",
    "    }\n",
    "    model.train()\n",
    "\n",
    "    label_ones =  torch.ones(1, data.x.shape[0]).to(args[\"device\"])\n",
    "    label_zeros = torch.zeros(1, data.x.shape[0]).to(args[\"device\"])\n",
    "\n",
    "    for epoch in tqdm(range(args['num_epoch'])):\n",
    "        optimizer.zero_grad()\n",
    "        loss_pos = 0\n",
    "        data = data.to(args['device'])\n",
    "        # forward(gat+linear)\n",
    "        h_ego, h_neighbor = model(data.x, data.edge_index)\n",
    "        h_ego_neg, h_neighbor_neg  = model.negative_sample(h_ego, h_neighbor)\n",
    "        # 算 -c\n",
    "        c_neighbor_pos = model.discriminator(h_ego, h_neighbor)\n",
    "        c_neighbor_neg = model.discriminator(h_ego, h_neighbor_neg)\n",
    "        c_ego_neg = model.discriminator(h_ego, h_ego_neg)\n",
    "        # rescal(x) = (x-(-1)) / 2，使介於0~1(原介於-1~1)\n",
    "        score_pos = rescale(c_neighbor_pos)\n",
    "        score_aug = rescale(c_neighbor_neg)\n",
    "        score_nod = rescale(c_ego_neg)\n",
    "        # BCE loss\n",
    "        # ego-neighbor postive, ego-neighbor negative, ego-ego negative\n",
    "        loss_pos = loss_function(score_pos, label_zeros)\n",
    "        loss_aug = loss_function(score_aug, label_ones)\n",
    "        loss_nod = loss_function(score_nod, label_ones)\n",
    "        loss_sum = loss_pos \\\n",
    "              + args['alpha'] * loss_aug \\\n",
    "              + args['gamma'] * loss_nod\n",
    "\n",
    "        loss_sum.backward()\n",
    "        # 只用postive判斷好壞\n",
    "        if loss_pos < stats[\"best_loss\"]:\n",
    "            stats[\"best_loss\"] = loss_pos.item()\n",
    "            stats[\"best_epoch\"] = epoch\n",
    "            torch.save(model.state_dict(), args['state_path'])\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    return stats\n",
    "\n",
    "def eval_model(args, data, model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data = data.to(args[\"device\"])\n",
    "        h_ego, h_neighbor = model(data.x, data.edge_index)\n",
    "        c_neighbor_pos = model.discriminator(h_ego, h_neighbor)\n",
    "        \n",
    "        y_true = (data.y).detach().cpu().tolist()\n",
    "        y_score = c_neighbor_pos.squeeze().detach().cpu().tolist()\n",
    "        auc = roc_auc_score(y_true, y_score)\n",
    "    return auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def set_random_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def run_experiment(args, data):\n",
    "    set_random_seeds(args['seed'])\n",
    "    # Create model\n",
    "    model = myGNN(args['enc_num_heads'], args['enc_input_dim'], args['enc_hidden_dim'],  args['enc_num_layers'], args[\"linear_output_dim\"])\n",
    "    model.to(args['device'])\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                 lr=args['lr'],\n",
    "                                 weight_decay=args['weight_decay'])\n",
    "    loss_function = torch.nn.BCELoss()\n",
    "    # train\n",
    "    stats = train_model(\n",
    "        args, data, model, optimizer, loss_function\n",
    "    )\n",
    "    # eval\n",
    "    model.load_state_dict(torch.load(args[\"state_path\"]))\n",
    "    auc = eval_model(args, data, model)\n",
    "    stats[\"AUC\"] = auc\n",
    "\n",
    "    return model, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\"lr\": 5e-4, \n",
    "        \"alpha\": 0.3, \n",
    "        \"gamma\": 0.4, \n",
    "        \"state_path\": \"model.pkl\", \n",
    "        \"device\": \"cuda:0\", \n",
    "        \"seed\": 1, \n",
    "        \"num_epoch\": 3, \n",
    "        \"weight_decay\": 0.0, \n",
    "        \"enc_num_heads\": 2, \n",
    "        \"enc_input_dim\":data.x.shape[1], \n",
    "        \"enc_hidden_dim\": 32, \n",
    "        \"linear_output_dim\": 64,\n",
    "        \"enc_num_layers\":2,\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_loss': 0.6684134602546692, 'best_epoch': 2, 'AUC': 0.6028277645581334}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model, stats = run_experiment(args, data)\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_proect",
   "language": "python",
   "name": "dl_proect"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
